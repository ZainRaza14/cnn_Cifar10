{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: [Syed Zain Raza]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run my code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "4. Upload this .HTML file to your Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/HM3/cnn.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#print (x_train[1])\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    a = OneHotEncoder(n_values = num_class)\n",
    "    b = a.fit_transform(y).toarray()\n",
    "    return b\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = np.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,362\n",
      "Trainable params: 551,466\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "# For regularization\n",
    "w_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(w_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(w_decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(w_decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(w_decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(w_decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(w_decay)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#dg = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "#dg.fit(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 0.0008 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001,decay=1e-6),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 1.5450 - acc: 0.4748 - val_loss: 1.2926 - val_acc: 0.5770ac\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 21s 525us/step - loss: 1.1120 - acc: 0.6407 - val_loss: 0.9409 - val_acc: 0.7057\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 21s 533us/step - loss: 0.9898 - acc: 0.6939 - val_loss: 0.9223 - val_acc: 0.7183\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 21s 533us/step - loss: 0.9252 - acc: 0.7230 - val_loss: 0.8717 - val_acc: 0.7475\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 22s 539us/step - loss: 0.8899 - acc: 0.7412 - val_loss: 0.8462 - val_acc: 0.7605\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 22s 545us/step - loss: 0.8477 - acc: 0.7598 - val_loss: 0.8648 - val_acc: 0.7579\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 22s 539us/step - loss: 0.8186 - acc: 0.7725 - val_loss: 0.8609 - val_acc: 0.7619\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 21s 532us/step - loss: 0.7953 - acc: 0.7826 - val_loss: 0.7871 - val_acc: 0.7916\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 21s 531us/step - loss: 0.7791 - acc: 0.7926 - val_loss: 0.8408 - val_acc: 0.7842- ETA: 6s - loss: 0 - ETA: 0s - loss: 0.7793 - a\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 21s 533us/step - loss: 0.7427 - acc: 0.8061 - val_loss: 0.8406 - val_acc: 0.7871\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 23s 587us/step - loss: 0.7310 - acc: 0.8132 - val_loss: 0.8346 - val_acc: 0.7949\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 22s 542us/step - loss: 0.7054 - acc: 0.8212 - val_loss: 0.8542 - val_acc: 0.7883\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 22s 543us/step - loss: 0.6875 - acc: 0.8302 - val_loss: 0.7975 - val_acc: 0.8081\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 22s 550us/step - loss: 0.6665 - acc: 0.8399 - val_loss: 0.7424 - val_acc: 0.8170\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 21s 536us/step - loss: 0.6489 - acc: 0.8438 - val_loss: 0.7636 - val_acc: 0.8177\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 22s 540us/step - loss: 0.6335 - acc: 0.8506 - val_loss: 0.7858 - val_acc: 0.8232\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 21s 535us/step - loss: 0.6238 - acc: 0.8547 - val_loss: 0.7629 - val_acc: 0.8234\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 21s 531us/step - loss: 0.6084 - acc: 0.8591 - val_loss: 0.7344 - val_acc: 0.8272\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 21s 531us/step - loss: 0.5902 - acc: 0.8648 - val_loss: 0.7459 - val_acc: 0.82675891 - ac - ETA: 1s - lo\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 21s 534us/step - loss: 0.5814 - acc: 0.8715 - val_loss: 0.7196 - val_acc: 0.8323\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=32, epochs=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcVNWZ//HP0y2KIAKyuLA1OEiUpoG2xQWCO6KJomgSCJlRTCQ6oI7+Mg4JTvBF4mQ1moxOEkzMGGVCHGdUzKAEo+CK0iiiQFBks0GxWeJCs3TD8/vj3Gqqi+qu6qWqevm+X6/7qrqn7q37UHTX0+ece84xd0dERKQuebkOQEREmj8lCxERSUnJQkREUlKyEBGRlJQsREQkJSULERFJSclCRERSUrIQEZGUlCxERCSlw3IdQFPp3r27FxQU5DoMEZEWZdmyZdvcvUeq41pNsigoKKC0tDTXYYiItChmtjGd49QMJSIiKSlZiIhISkoWIiKSUqvps0imsrKSsrIy9uzZk+tQpA7t27end+/etGvXLtehiEgtWnWyKCsro1OnThQUFGBmuQ5HknB3tm/fTllZGf379891OCJSi1bdDLVnzx66deumRNGMmRndunVT7U+kAebMgYICyMsLj3PmZO5arbpmAShRtAD6PxKpvzlzYMoUqKgI+xs3hn2ASZOa/nqtumYhItJazZhxMFHEVFSE8kxQssig7du3M2zYMIYNG8Zxxx1Hr169qvf37duX1ntMnjyZNWvW1HnMfffdx5xM1j9FpNnZtKl+5Y2lZBGnqdv/unXrxvLly1m+fDnXX389t9xyS/X+4YcfDoQO3gMHDtT6Hr/73e8YNGhQndeZOnUqkzJR7xSRjGrMd07fvvUrbywli0is/W/jRnA/2P6XiT/Y165dS2FhIddffz3FxcV88MEHTJkyhZKSEgYPHsysWbOqjx01ahTLly+nqqqKLl26MH36dIYOHcqZZ57JRx99BMDtt9/OPffcU3389OnTGTFiBIMGDeLll18GYNeuXVx55ZUMHTqUiRMnUlJSwvLlyw+JbebMmZx22mnV8bk7AO+88w7nnXceQ4cOpbi4mA0bNgDwb//2bwwZMoShQ4cyI1P1X5FWqLHfOXfeCR061Czr0CGUZ4S7t4rt1FNP9USrVq06pKw2/fq5h/+ymlu/fmm/RZ1mzpzpP/nJT9zd/d1333Uz89dee6369e3bt7u7e2VlpY8aNcpXrlzp7u4jR470N954wysrKx3w+fPnu7v7Lbfc4j/4wQ/c3X3GjBl+9913Vx9/2223ubv7E0884RdddJG7u//gBz/wf/zHf3R39+XLl3teXp6/8cYbh8QZi+PAgQM+YcKE6usVFxf7vHnz3N199+7dvmvXLp83b56PGjXKKyoqapzbEPX5vxJpLh5+OHxHmIXHhx9O/9ym+M5pzPVjgFJP4ztWNYtIttv/TjzxRE477bTq/T/84Q8UFxdTXFzM6tWrWbVq1SHnHHnkkVx88cUAnHrqqdV/3ScaP378Ice8+OKLTJgwAYChQ4cyePDgpOf+5S9/YcSIEQwdOpTFixezcuVKdu7cybZt27j00kuBMIiuQ4cOPPPMM1x77bUceeSRABxzzDH1/yBEWqjG1gya4jtn0iTYsAEOHAiPmWyNVrKIZLv9r2PHjtXP3333XX7+85/z7LPPsmLFCsaOHZt03EGsnwMgPz+fqqqqpO99xBFHHHKMR81JdamoqGDatGk89thjrFixgmuvvbY6jmS3t7q7bnuVNquxdyNl+zunsZQsIllv/4vzySef0KlTJ44++mg++OADFixY0OTXGDVqFI888ggAb731VtKay+7du8nLy6N79+58+umn/M///A8AXbt2pXv37jz55JNAGOxYUVHBmDFj+O1vf8vu3bsB2LFjR5PHLZJJjelgbmzNIJffOQ2R0WRhZmPNbI2ZrTWz6Ule72tmz5nZG2a2wswuicoLzGy3mS2Ptl9lMk4I1bfZs6FfPzALj7NnZ7ZaF1NcXMwpp5xCYWEh1113HSNHjmzya9x4441s3ryZoqIi7rrrLgoLC+ncuXONY7p168bVV19NYWEhV1xxBaeffnr1a3PmzOGuu+6iqKiIUaNGUV5ezhe/+EXGjh1LSUkJw4YN4+67727yuEUypbHNSI2tGeTyO6dB0unYaMgG5APvAQOAw4E3gVMSjpkN3BA9PwXYED0vAN6uz/Ua28Hd2lVWVvru3bvd3f2dd97xgoICr6yszHFUB+n/Shoilx3MDz/s3qFDzXM7dGhYJ3MukWYHdyan+xgBrHX3dQBmNhcYB8S3fzhwdPS8M7Alg/G0aZ999hnnn38+VVVVuDu//vWvOeywVj/bi7RijZ3uorHNSLFrzJgRzunbNzQhNduaQSNl8tuiF/B+3H4ZcHrCMXcAfzazG4GOwAVxr/U3szeAT4Db3f2FDMba6nXp0oVly5blOgyRJlNXB3M6X9h9+4YEk6w8XZMmtd7kkCiTfRbJbpNJvCVnIvCf7t4buAR4yMzygA+Avu4+HLgV+C8zOzrhXMxsipmVmllpeXl5E4cvIpmmDuaWI5PJogzoE7ffm0Obmb4OPALg7q8A7YHu7r7X3bdH5csIfR8nJV7A3We7e4m7l/To0SMD/wQRyRR1MLcsmUwWS4GBZtbfzA4HJgDzEo7ZBJwPYGYnE5JFuZn1MLP8qHwAMBBYl8FYRaQBGlMzaOw4haaoGWRzUFtLl7Fk4e5VwDRgAbAaeMTdV5rZLDO7LDrs/wHXmdmbwB+Aa6Le+dHAiqj8UeB6d9dN/CLNSK5HMKtmkGXp3DLVErbmeOvs2Wef7U8//XSNsrvvvttvuOGGOs/r2LGju7tv3rzZr7zyylrfe+nSpXW+z9133+27du2q3r/44ot9586d6YSedbn+v5L6a+ytp5mej03Sg+aGyr2JEycyd+7cGmVz585l4sSJaZ1/wgkn8Oijjzb4+vfccw8VcfX8+fPn06VLlwa/n0g8dTC3LUoWGXTVVVfxpz/9ib179wKwYcMGtmzZwqhRo6rHPRQXFzNkyBCeeOKJQ87fsGEDhYWFQJiKY8KECRQVFfGVr3yleooNgBtuuKF6evOZM2cC8Itf/IItW7Zw7rnncu655wJQUFDAtm3bAPjZz35GYWEhhYWF1dObb9iwgZNPPpnrrruOwYMHM2bMmBrXiXnyySc5/fTTGT58OBdccAFbt24FwliOyZMnM2TIEIqKiqqnC3n66acpLi5m6NChnH/++U3y2UruqYO5jUmn+tEStpTNUDff7H722U273XxzXbU7d3e/5JJL/PHHH3f3ME34t771LXcPI6o//vhjd3cvLy/3E0880Q8cOODuB5uh1q9f74MHD3Z397vuussnT57s7u5vvvmm5+fnVzdDxaYGr6qq8rPPPtvffPNNd3fv16+fl5eXV8cS2y8tLfXCwkL/7LPP/NNPP/VTTjnFX3/9dV+/fr3n5+dXT13+pS99yR966KFD/k07duyojvX+++/3W2+91d3db7vtNr857jPZsWOHf/TRR967d29ft25djVgTqRkqNxozArq1jGBu8Q4ccI9rbq4v1AzVPMQ3RcU3Qbk73/nOdygqKuKCCy5g8+bN1X+hJ/P888/zta99DYCioiKKioqqX3vkkUcoLi5m+PDhrFy5MukkgfFefPFFrrjiCjp27MhRRx3F+PHjeeGFMOaxf//+DBs2DKh9GvSysjIuuugihgwZwk9+8hNWrlwJwDPPPMPUqVOrj+vatStLlixh9OjR9O/fH9A05s1JYzuoVTPIgU8/hVdegfvvh5tugvPOg5494QtfyPil2858D1FTS7Zdfvnl3Hrrrbz++uvs3r2b4uJiIEzMV15ezrJly2jXrh0FBQVJpyWPl2w68PXr1/PTn/6UpUuX0rVrV6655pqU7xP+mEguNr05hCnOkzVD3Xjjjdx6661cdtllLFq0iDvuuKP6fRNjTFYmzUNjR0BD2xrBnFX79sGaNfDWW/D22+HxrbdqDjnv2BEKC+Hyy+GMMzIeUttJFjly1FFHcc4553DttdfW6Nj++OOP6dmzJ+3ateO5555jY7J5B+KMHj2aOXPmcO655/L222+zYsUKIExv3rFjRzp37szWrVt56qmnOOeccwDo1KkTn376Kd27dz/kva655hqmT5+Ou/PYY4/x0EMPpf1v+vjjj+nVqxcADz74YHX5mDFjuPfee6v7QHbu3MmZZ57J1KlTWb9+Pf3792fHjh2qXTQT2V7wq1X59NPwQcW2zz6Dww5r+LZ1a83EsGYNxNarOewwGDQIzjwzVP0KC2HIkFCVy8te45CSRRZMnDiR8ePH17gzatKkSVx66aXV03t/7nOfq/M9brjhBiZPnkxRURHDhg1jxIgRQFj1bvjw4QwePJgBAwbUmN58ypQpXHzxxRx//PE899xz1eXFxcVcc8011e/xjW98g+HDh9e68l6iO+64gy996Uv06tWLM844g/Xr1wNhLfCpU6dSWFhIfn4+M2fOZPz48cyePZvx48dz4MABevbsycKFC9O6jqQ2Z07DJ7JrirmRWqUDB+DDD8OHunHjwYQQ/3znzsxcu6AgJIPLLgsJobAwJIq4hc9yxepqkmhJSkpKvLS0tEbZ6tWrOfnkk3MUkdSH/q/qL3HWVQi3nqbbb9DY83Pu449h5cqwbd8eOl4OHDj0MVlZ4uOOHQcTQlkZVFbWvFaXLiGLxrZ+/WruH3007N8fagP13SoroWtXGDw4vE+Wmdkydy9JdZxqFiItVGP7HFrMFNsVFbB6dWiiWbkyPL79Nrz/fupzIfS+5+XV/dilS0gAZ55ZezJo45QsRFqopuhzaFYd1Pv2wTvvHEwGseTw3nuhBgBwxBHwuc/B6NGhiSa29ewJ+fnJE4E0iVafLHQ3TvPXWppCG6LF9zlUVMDzz8PmzeHLvrKy5mOysmSvvf9+zU7d/Hw46SQYNgy+9rWDSeHEE0OHr2Rdq/7U27dvz/bt2+nWrZsSRjPl7mzfvp327dvnOpSsa+xKb3fembzPIaPTZbiHu3UWLAjbCy+EL/va5OeHztl27Wp/bNcOBgwInbqxpDBoUKhFSLPRqju4KysrKSsrSznuQHKrffv29O7dm3bt2uU6lKwqKEheM+jXL0yXnY7G1EzSVl4OzzwTksOf/wwffBDKCwvhoovCFrtjJzERZPHWTmmYdDu4W3WyEGnO8vIONsXHMws36ORMZWUYJRyrPbz+egj0mGPgwgtDchgzBqKxNtKy6W4okSxo8X0OMe+9d7Dm8OyzYdBZfn64O2jWrJAgiotDmbRJShYiDdQi+xwSLVkC06bBsmVhv6AAvvrVkBzOOw86d85iMNKcZbRB0czGmtkaM1trZtOTvN7XzJ4zszfMbIWZXRL32rej89aY2UWZjFOkIRq7LGhOJ+LbuROuvx7OOiuMVr7nnnA30rp18KtfwRVXKFFIDRnrs4jW0H4HuBAoI6zJPdHdV8UdMxt4w91/aWanAPPdvSB6/gdgBHAC8Axwkrvvr+166rOQbGu2fQ51cQ9VoltvDaOWb74Z7rgDOnXKdWSSI+n2WWSyZjECWOvu69x9HzAXGJdwjAOxoZGdgS3R83HAXHff6+7rgbXR+4k0G41d/Cfr/vpXOP98+Pu/D7eqlpbCXXcpUUhaMpksegHx4/HLorJ4dwBfM7MyYD5wYz3OFcmpFrMs6O7dcPvtUFQEb7wRmplefjkMeBNJUyaTRbJRcImV9onAf7p7b+AS4CEzy0vzXMxsipmVmllpeXl5owMWqY8WsfjP00+H8RB33gkTJoTaxTe/qfEPUm+Z/IkpA/rE7ffmYDNTzNeBRwDc/RWgPdA9zXNx99nuXuLuJT169GjC0KWtmDMn3ACUlxce010lLmbSpDCA7sCB8FjvRPG3v4Uv9MWLw+2qTWXzZvjSl+Dii8PguGefhd//Ho49tumuIW1KJm+dXQoMNLP+wGZgAvDVhGM2AecD/2lmJxOSRTkwD/gvM/sZoYN7IPBaBmOVNqixt742yEcfhSkynn8+bG++ebCX3CxMknfaaVBSEh6HDYP6TIVSVQX33Reanaqq4Pvfh299S1NnSKNldAR3dCvsPUA+8IC732lmswgLhM+L7nq6HziK0Mx0m7v/OTp3BnAtUAX8k7s/Vde1dDdUG7V7N3z3u+Fx5MiwpdnD3BTTbaRUVnYwMSxeHJqBAI48Mty2Ono0fP7zIf7SUli6NGyx9dgPOyw0I8UnkMLCUFtI9Npr4XbYN96AsWPh3nvDxHsiddB0H9L6ffwxjBsXvog7dIBdu0J5794HE8fIkaFjN8lMpU1+66t7GAkdSw7PPw/RKoIcfXRICqNHh624uPbVz9xDM9LSpQcTSGnpwdXZjjgi1DhiCaSoCO6/P3RcH398GDNx1VWanlvSomQhrdtHH8HYsRxY8RY3d32IX227ijHHreCOMS9x2t6X4KWXwl/1AEcdBaeffjB5nHEGHH10w2oWBw7Atm3hL//Y9uGH4cv8+edhS9S11r37wcQwenT4Qm/MVBnuYcBcrOZRWhpGXccSZF4e3HhjmJpDC/VIPShZSOu1YQOMGUPVxjKusv/lib1jq1+qsSzopk0hacS2FSvCl31eHgwZwjs9RvKD50fy7L6R7KE9x/Eh/Y7YyvTJWznrxK01E0JsKy8Py2cm6tULzj77YHL43Ocy/5f9/v1h1PXrr4dkVFSU2etJq6RkIa3TqlVhxtNduxh/xP/x2NazDjmk1prBJ5/Aq68eTB5LlsBnn9V+rfbtw91DdW3HHRceO3dWs4+0SJp1VlqfV1+FSy4Jbf2LF/P4sOR/Sde6rOjRR4cpti+8MOxXVYWFfF55JTTzJCaBTp2UAEQiShbSMixcGCa3O/bY8HzAgMZP8X3YYTB8eNhEpE4axinN36OPwhe+EOYzevHF8EgLmm5DpBVQspCcSjmC+v774ctfhhEjwjiF44+vfqlFTLch0kqoGUpyps4R1F91+NGP4NvfDlNWPProodUIQmJQchDJPNUsJGdqXTzoOw633RYSxVe/Ck88kTRRiEj2KFlIziS7aymfKmZu+jr89KcwdSo89FDyqS1EJKuULCRnEu9aOoI9PMpVTOZ3MHMm/Pu/ayptkWZCv4mSM/F3M3XiE57iYi7nCUr//udhqU+NcRBpNpQspFEasx5E7G6m4b3LeZbz+Dwv8NIND1Py+5syFa6INJDuhpIwU2plZZj87phj0m76qdd6EPv2wfvvh3k44rZJGzcyqWIltK+AR59g5Be+0ET/KBFpSkoWbdXu3fDII/DrX4fpLmLy8qBbt5A4evQ4uMXvR89/8S89qKroDhzB4eylL5voV7GRFTdtYNLqDQeTwsaNYcrt+HnI8vKgT59QHbn00rAOwxlnZPUjEJH0KVm0NX/9a0gQDz4Y1kcYNAjuuisMdisvD9u2bQefr14dpt7evv2QRR5ejR4/oyMdqCAvtkz6DuCH+QeTwQUXhMeCgjByrqAgzNKqu5xEWoyMJgszGwv8nLBS3m/c/YcJr98NnBvtdgB6unuX6LX9wFvRa5vc/bJMxtqq7d0Ljz0WFsdZvDh8SY8fH/6aP/vs9DqS9+8P60XHkkh5Od++bht5O8rpzjZ20pUNFLCBAvb36sdLG3olXXBIRFqmjP02m1k+cB9wIVAGLDWzee6+KnaMu98Sd/yNQPyMbrvdfVim4msT3nsv9CA/8ECoLQwYAD/8IUyeDD171u+98vND81S3bmGtBqBwd80+C4jWk/gRqrOKtDKZ/JUeAax193UAZjYXGAesquX4icDMDMbTNlRWwrx5oalp4cLwJT9uHHzzm6E5qAnHLcQ6sWfMCAPs+vYNt8Nq+g2R1ieTyaIX8H7cfhlwerIDzawf0B94Nq64vZmVAlXAD9398UwF2ips3Bgm3fvtb8Myn336wPe+B9deCyeckLHLam4mkbYhk8kiWUN4bcvyTQAedff49Sr7uvsWMxsAPGtmb7n7ezUuYDYFmALQN+1FDFqZnTvhG98IfRJmYXGg66+HsWMbt+aziEicTA7KKwP6xO33BrbUcuwE4A/xBe6+JXpcByyiZn9G7JjZ7l7i7iU9evRoiphbli1bwnrPf/oTfOc7sH49PPlkWPshzUTRmEF1ItJ2ZLJmsRQYaGb9gc2EhPDVxIPMbBDQFXglrqwrUOHue82sOzAS+HEGY2151qyBiy6CHTvgqafgvPPq/Rb1GlQnIm1axmoW7l4FTAMWAKuBR9x9pZnNMrP422AnAnPd40dscTJQamZvAs8R+ixq6xhve157DUaODAPrFi1qUKKAOqYIn9H4EEWkdbGa39EtV0lJiZeWluY6jMxbsACuvDKsRb1gAfzd3zX4rfLyag6qjjE7ZPydiLRSZrbM3UtSHaeJBFuSOXPgi1+EgQPhpZcalSjg0CnCU5WLSNulZNFS3HMPfO1rMGpUaHo67rhGv2X8FOExHTqEchGReEoWzZ07TJ8Ot9wSmp+eego6d26St45NEd6vX2h66tcv7KtzW0QSaVKG5qyqKtye9LvfhbET997b5GMnNKhORNKhmkVzVVEBV1wREsUdd8B//IcG2YlIzihZNEc7dsCYMfB//we//GVYj7qWmWE1qE5EskHNUM1NWVmYquPdd8PiRFddVeuhGlQnItmimkVzsno1nHVWmML16afrTBSgQXUikj2qWTQXr74aJgFs1y4sUDT8kKmwDrFpU/3KRUQaSjWL5mD+/DBlR9euYbBdGokCNKhORLJHySJXdu0KdzqNHBlmiR00KCSKE09M+y00qE5EskXJIpvcobQ0jJk4/viwMNH27fDjH4emp2OPrdfbaVCdiGRLyj4LM5sGzHH3nVmIp3X629/CrUu/+Q0sXw5HHglf/nJYtGjkyFpvi02HBtWJSDak08F9HLDUzF4HHgAWeGuZqjaT3OGFF0KC+O//hj17Ql/Ef/wHTJwIXbrkOkIRkbSlTBbufruZ/SswBpgM3GtmjwC/TVzmVICtW+H3vw9J4p134OijYfLkUIsoLs51dCIiDZLWrbPu7mb2IfAhUEVY2e5RM1vo7rdlMsAWYf9+WLgwJIgnnghzOo0aFZY6veoq6Ngx1xGKiDRKOn0WNwFXA9uA3wD/7O6VZpYHvAvUmizMbCzwcyAf+I27/zDh9buBc6PdDkBPd+8SvXY1cHv02vfd/cH6/MOyZs8eOP10WLECuneHm2+Gr38dTj4515GJiDSZdGoW3YHx7r4xvtDdD5jZF2s7yczygfuAC4EyQr/HvPjlUd39lrjjbwSGR8+PAWYCJYADy6Jzm18n+5IlIVH8+MchURx+eK4jEhFpcuncOjsf2BHbMbNOZnY6gLuvruO8EcBad1/n7vuAucC4Oo6fCPwhen4RsNDdd0QJYiEwNo1Ys2/RojCL35QpShQi0mqlkyx+CXwWt78rKkulF/B+3H5ZVHYIM+sH9Aeere+5ObdoUei4bqIFiUREmqN0koXF3yrr7gdIr/kq2eCB2m65nQA86u7763OumU0xs1IzKy0vL08jpCa2Z09ohjr77Aa/haYYF5GWIJ1ksc7MbjKzdtF2M7AujfPKgD5x+72BLbUcO4GDTVBpn+vus929xN1LevTokUZITWzJEti7F845p0Gnx6YY37gxDMuITTGuhCEizU06yeJ64CxgM+FL/HRgShrnLQUGmll/MzuckBDmJR5kZoMIt+K+Ele8ABhjZl3NrCthjMeCNK6ZXbH+ilGjGnS6phgXkZYinUF5HxG+6OvF3auiqUIWEG6dfcDdV5rZLKDU3WOJYyIwN6Gpa4eZfY+QcABmufsOmptFi8Ko7AaOxtYU4yLSUqQzzqI98HVgMNA+Vu7u16Y6193nE+6mii/7bsL+HbWc+wBhepHmKdZfMW1ag9+ib9/Q9JSsXESkOUmnGeohwvxQFwGLCf0Hn2YyqBahkf0VoCnGRaTlSCdZ/J27/yuwKxpF/QVgSGbDagEWL25UfwVoinERaTnSuQW2Mnr8m5kVEuaHKshYRC1FI/srYjTFuIi0BOnULGZHdyTdTribaRXwo4xG1dzt2QOvvNKoJigRkZakzppFNFngJ9GUG88DA7ISVXP36quN7q8QEWlJ6qxZRKO1G367T2vVyPEVIiItTTrNUAvN7Ftm1sfMjoltGY+sOWui/goRkZYinQ7u2HiKqXFlTlttkor1VzRifIWISEuTzgju/tkIpMVQf4WItEHpjOD+h2Tl7v77pg+nBVB/hYi0Qek0Q50W97w9cD7wOtB2k8WwYeqvEJE2JZ1mqBvj982sM2EKkLYn1l8xdWrqY0VEWpF07oZKVAEMbOpAWgT1V4hIG5VOn8WTHFylLg84BXgkk0E1W4sWhUmcPv/5XEciIpJV6fRZ/DTueRWw0d3LMhRP86bxFSLSRqWTLDYBH7j7HgAzO9LMCtx9Q0Yja27UXyEibVg6fRb/DRyI298flaVkZmPNbI2ZrTWz6bUc82UzW2VmK83sv+LK95vZ8mg7ZDnWrFN/hYi0YenULA5z932xHXffF62pXSczywfuAy4krN291MzmufuquGMGAt8GRrr7TjPrGfcWu919WLr/kIxTf4WItGHp1CzKzeyy2I6ZjQO2pXHeCGCtu6+Lks1cYFzCMdcB90Wz2sbW+26e1F8hIm1YOsnieuA7ZrbJzDYB/wJ8M43zegHvx+2XRWXxTgJOMrOXzGyJmY2Ne629mZVG5Zencb3M0foVItLGpTMo7z3gDDM7CjB3T3f9bUv2dkmuPxA4h7C29wtmVujufwP6uvsWMxsAPGtmb0WxHLyA2RRgCkDfvn3TDKsBXntN/RUi0qalrFmY2b+ZWRd3/8zdPzWzrmb2/TTeuwzoE7ffG9iS5Jgn3L3S3dcDa4gG/Ln7luhxHbAIGJ54AXef7e4l7l7So0ePNEJqoDr6K+bMgYKCMF1UQUHYFxFpbdJphro4+ksfgKh/4ZI0zlsKDDSz/lGH+ATCsqzxHgfOBTCz7oRmqXVRQjoirnwkYTnX3Kilv2LOHJgyBTZuBPfwOGWKEobitUGDAAAO2ElEQVSItD7pJIv82Bc3hHEWwBF1HA+Au1cRVtlbAKwGHnH3lWY2K67DfAGw3cxWAc8B/+zu24GTgVIzezMq/2H8XVRZVUd/xYwZUFFRs6yiIpSLiLQm6dw6+zDwFzP7XbQ/GXgwnTd39/nA/ISy78Y9d+DWaIs/5mVgSDrXyLjXXgsJ4+yzD3lp06bkp9RWLiLSUqXTwf1jM1sBXEDotH4a6JfpwJqNOvor+vYNTU/JykVEWpN0Z539kDCK+0rCeharMxZRcxNbv6Jr10NeuvNO6NChZlmHDqFcRKQ1qTVZmNlJZvZdM1sN3EsYM2Hufq6735u1CHMpxfiKSZNg9mzo1y9UPvr1C/uTJmU3TBGRTKurGeqvwAvApe6+FsDMbslKVM1FrL+ijvEVkyYpOYhI61dXM9SVhOan58zsfjM7n+QD7VovzQclIgLUkSzc/TF3/wrwOcKguFuAY83sl2Y2Jkvx5VYd/RUiIm1Jyg5ud9/l7nPc/YuEUdjLgaTTjbcqmg9KRKRavdbgdvcd7v5rdz8vUwE1G2n0V4iItBX1ShZtivorRESqKVnURv0VIiLVlCySUX+FiEgNShbJqL9CRKQGJYtk1F8hIlKDkkUyixfD0KHqrxARiShZJNq7F15+WU1QIiJxlCwSqb9CROQQGU0WZjbWzNaY2VozSzrq28y+bGarzGylmf1XXPnVZvZutF2dyThrUH+FiMgh0lkpr0HMLB+4D7gQKAOWmtm8+OVRzWwg8G1gpLvvNLOeUfkxwEygBHBgWXTuzkzFW23RotBfccwxGb+UiEhLkcmaxQhgrbuvc/d9wFxgXMIx1wH3xZKAu38UlV8ELIymF9kJLATGZjDWQP0VIiJJZTJZ9CIsmBRTFpXFOwk4ycxeMrMlZja2Huc2PfVXiIgklbFmKJKvfeFJrj8QOIcwo+0LZlaY5rmY2RRgCkDfplj4Wv0VIiJJZbJmUQb0idvvDWxJcswT7l7p7uuBNYTkkc65uPtsdy9x95IePXo0PmL1V4iIJJXJZLEUGGhm/c3scGACMC/hmMeBcwHMrDuhWWodsAAYY2ZdzawrMCYqyxz1V4iI1CpjzVDuXmVm0whf8vnAA+6+0sxmAaXuPo+DSWEVsB/4Z3ffDmBm3yMkHIBZ7r4jU7EC6q8QEalDJvsscPf5wPyEsu/GPXfg1mhLPPcB4IFMxleD+itERGqlEdwx6q8QEamVkgWov0JEJAUlC1B/hYhICkoWoP4KEZEUlCwgJIuiIvVXiIjUQslC/RUiIikpWWzfHhLFmDG5jkREpNnK6DiLFuGEE+Cpp3IdhYhIs6aahYiIpKRkISIiKSlZiIhISkoWIiKSkpKFiIikpGQhIiIpKVmIiEhKShYiIpJSRpOFmY01szVmttbMpid5/RozKzez5dH2jbjX9seVJy7HKiIiWZSxEdxmlg/cB1wIlAFLzWyeu69KOPSP7j4tyVvsdvdhmYpPRETSl8maxQhgrbuvc/d9wFxgXAavJyIiGZLJZNELeD9uvywqS3Slma0ws0fNrE9ceXszKzWzJWZ2ebILmNmU6JjS8vLyJgxdRETiZTJZWJIyT9h/Eihw9yLgGeDBuNf6unsJ8FXgHjM78ZA3c5/t7iXuXtKjR4+miltERBJkMlmUAfE1hd7AlvgD3H27u++Ndu8HTo17bUv0uA5YBAzPYKwiIlKHTCaLpcBAM+tvZocDE4AadzWZ2fFxu5cBq6PyrmZ2RPS8OzASSOwYFxGRLMnY3VDuXmVm04AFQD7wgLuvNLNZQKm7zwNuMrPLgCpgB3BNdPrJwK/N7AAhof0wyV1UIiKSJeae2I3QMpWUlHhpaWmuwxARaVHMbFnUP1wnjeAWEZGUlCxERCQlJQsREUlJyUJERFJSshARkZSULEREJCUlCxERSUnJQkREUlKyEBGRlJQsREQkJSULERFJSclCRERSUrIQEZGUlCxERCQlJQsREUlJyUJERFLKaLIws7FmtsbM1prZ9CSvX2Nm5Wa2PNq+Effa1Wb2brRdnck4RUSkbhlbVtXM8oH7gAuBMmCpmc1LsjzqH919WsK5xwAzgRLAgWXRuTszFa+IiNQukzWLEcBad1/n7vuAucC4NM+9CFjo7juiBLEQGJuhOEVEJIVMJotewPtx+2VRWaIrzWyFmT1qZn3qc66ZTTGzUjMrLS8vb6q4RUQkQSaThSUp84T9J4ECdy8CngEerMe5uPtsdy9x95IePXo0KlgREaldJpNFGdAnbr83sCX+AHff7u57o937gVPTPVdERLInk8liKTDQzPqb2eHABGBe/AFmdnzc7mXA6uj5AmCMmXU1s67AmKhMRERyIGN3Q7l7lZlNI3zJ5wMPuPtKM5sFlLr7POAmM7sMqAJ2ANdE5+4ws+8REg7ALHffkalYRUSkbuZ+SFdAi1RSUuKlpaW5DkNEpEUxs2XuXpLqOI3gFhGRlJQsREQkJSULERFJSclCRERSavPJYs4cKCiAvLzwOGdOriMSEWl+MnbrbEswZw5MmQIVFWF/48awDzBpUu7iEhFpbtp0zWLGjIOJIqaiIpSLiMhBbTpZbNpUv3IRkbaqTSeLvn3rVy4i0la16WRx553QoUPNsg4dQrmIiBzUppPFpEkwezb06wdm4XH2bHVui4gkatN3Q0FIDEoOIiJ1a9M1CxERSY+ShYiIpKRkISIiKSlZiIhISkoWIiKSUqtZKc/MyoGNjXiL7sC2JgonExRf4yi+xlF8jdOc4+vn7j1SHdRqkkVjmVlpOksL5oriaxzF1ziKr3Gae3zpUDOUiIikpGQhIiIpKVkcNDvXAaSg+BpH8TWO4muc5h5fSuqzEBGRlFSzEBGRlNpUsjCzsWa2xszWmtn0JK8fYWZ/jF5/1cwKshhbHzN7zsxWm9lKM7s5yTHnmNnHZrY82r6brfjiYthgZm9F1y9N8rqZ2S+iz3CFmRVnMbZBcZ/NcjP7xMz+KeGYrH6GZvaAmX1kZm/HlR1jZgvN7N3osWst514dHfOumV2dxfh+YmZ/jf7/HjOzLrWcW+fPQgbju8PMNsf9H15Sy7l1/r5nML4/xsW2wcyW13Juxj+/JuXubWID8oH3gAHA4cCbwCkJx/wj8Kvo+QTgj1mM73igOHreCXgnSXznAH/K8ee4Aehex+uXAE8BBpwBvJrD/+8PCfeQ5+wzBEYDxcDbcWU/BqZHz6cDP0py3jHAuuixa/S8a5biGwMcFj3/UbL40vlZyGB8dwDfSuP/v87f90zFl/D6XcB3c/X5NeXWlmoWI4C17r7O3fcBc4FxCceMAx6Mnj8KnG9mlo3g3P0Dd389ev4psBrolY1rN7FxwO89WAJ0MbPjcxDH+cB77t6YgZqN5u7PAzsSiuN/zh4ELk9y6kXAQnff4e47gYXA2GzE5+5/dveqaHcJ0Lupr5uuWj6/dKTz+95odcUXfXd8GfhDU183F9pSsugFvB+3X8ahX8bVx0S/LB8D3bISXZyo+Ws48GqSl880szfN7CkzG5zVwAIH/mxmy8xsSpLX0/mcs2ECtf+S5vozPNbdP4DwRwLQM8kxzeVzvJZQU0wm1c9CJk2LmskeqKUZrzl8fp8Htrr7u7W8nsvPr97aUrJIVkNIvBUsnWMyysyOAv4H+Cd3/yTh5dcJzSpDgX8HHs9mbJGR7l4MXAxMNbPRCa83h8/wcOAy4L+TvNwcPsN0NIfPcQZQBcyp5ZBUPwuZ8kvgRGAY8AGhqSdRzj8/YCJ11ypy9fk1SFtKFmVAn7j93sCW2o4xs8OAzjSsCtwgZtaOkCjmuPv/Jr7u7p+4+2fR8/lAOzPrnq34outuiR4/Ah4jVPfjpfM5Z9rFwOvuvjXxhebwGQJbY01z0eNHSY7J6ecYdah/EZjkUQN7ojR+FjLC3be6+353PwDcX8t1c/35HQaMB/5Y2zG5+vwaqi0li6XAQDPrH/3lOQGYl3DMPCB218lVwLO1/aI0tah987fAanf/WS3HHBfrQzGzEYT/v+3ZiC+6Zkcz6xR7TugIfTvhsHnAP0R3RZ0BfBxrcsmiWv+iy/VnGIn/ObsaeCLJMQuAMWbWNWpmGROVZZyZjQX+BbjM3StqOSadn4VMxRffB3ZFLddN5/c9ky4A/uruZclezOXn12C57mHP5ka4U+cdwl0SM6KyWYRfCoD2hKaLtcBrwIAsxjaKUE1eASyPtkuA64Hro2OmASsJd3YsAc7K8uc3ILr2m1Ecsc8wPkYD7os+47eAkizH2IHw5d85rixnnyEhaX0AVBL+2v06oR/sL8C70eMx0bElwG/izr02+llcC0zOYnxrCe39sZ/D2B2CJwDz6/pZyFJ8D0U/WysICeD4xPii/UN+37MRX1T+n7Gfubhjs/75NeWmEdwiIpJSW2qGEhGRBlKyEBGRlJQsREQkJSULERFJSclCRERSUrIQScHM9ifMZttkM5iaWUH8jKUizdVhuQ5ApAXY7e7Dch2ESC6pZiHSQNF6BD8ys9ei7e+i8n5m9pdooru/mFnfqPzYaH2IN6PtrOit8s3sfgvrmPzZzI6Mjr/JzFZF7zM3R/9MEUDJQiQdRyY0Q30l7rVP3H0EcC9wT1R2L2Ga9iLCJHy/iMp/ASz2MIlhMWHkLsBA4D53Hwz8DbgyKp8ODI/e5/pM/eNE0qER3CIpmNln7n5UkvINwHnuvi6aBPJDd+9mZtsIU1BURuUfuHt3MysHerv73rj3KCCsWzEw2v8XoJ27f9/MngY+I8yM+7hHEyCK5IJqFiKN47U8r+2YZPbGPd/Pwb7ELxDm2ToVWBbNZCqSE0oWIo3zlbjHV6LnLxNmOQWYBLwYPf8LcAOAmeWb2dG1vamZ5QF93P054DagC3BI7UYkW/SXikhqR5rZ8rj9p909dvvsEWb2KuEPr4lR2U3AA2b2z0A5MDkqvxmYbWZfJ9QgbiDMWJpMPvCwmXUmzOR7t7v/rcn+RSL1pD4LkQaK+ixK3H1brmMRyTQ1Q4mISEqqWYiISEqqWYiISEpKFiIikpKShYiIpKRkISIiKSlZiIhISkoWIiKS0v8H+/Nt5pssZKUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.001,decay=1e-6),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 27s 535us/step - loss: 0.6468 - acc: 0.8492\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 0.6243 - acc: 0.8581\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 0.6125 - acc: 0.8609\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.5995 - acc: 0.8649\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 0.5885 - acc: 0.8690\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.5816 - acc: 0.87110s - loss: 0.5818 - acc:\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.5751 - acc: 0.8742\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 0.5722 - acc: 0.8757\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 25s 498us/step - loss: 0.5654 - acc: 0.87898s - loss: 0.5556 - acc: 0.8 - ETA: 8s - lo - ETA: 4s - loss: 0.5605 - - ETA: 3s - loss: 0.561 - \n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 0.5638 - acc: 0.878511s - los - ETA: - ETA: 1s - loss: 0.5627 - acc: 0. - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.5642 - acc: 0.\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.5550 - acc: 0.881310s - loss: 0.5486 - acc - ETA: 9s - loss: 0.5491 - a - ETA: 9s - - ETA: - ETA: 0s - loss: 0.5539 - acc:\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 25s 496us/step - loss: 0.5552 - acc: 0.8820\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 25s 498us/step - loss: 0.5515 - acc: 0.8833\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 25s 500us/step - loss: 0.5458 - acc: 0.88441s - loss: 0.5441 - ETA: 0s - loss: 0.5459 - acc: 0.\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 0.5490 - acc: 0.88640s - loss: 0.5480 - \n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 25s 503us/step - loss: 0.5409 - acc: 0.88781s -\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 26s 528us/step - loss: 0.5396 - acc: 0.8879\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 0.5373 - acc: 0.88831s - los\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 25s 503us/step - loss: 0.5390 - acc: 0.8911\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 25s 496us/step - loss: 0.5392 - acc: 0.8896\n"
     ]
    }
   ],
   "source": [
    "#Train your model on the entire training set (50K samples)>\n",
    "#Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
    "#Do NOT use the validation_data option (because now you do not have validation data)>\n",
    "\n",
    "#dg.fit(x_train)\n",
    "\n",
    "history = model.fit(x_train, y_train_vec, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 338us/step\n",
      "loss = 0.7075126354217529\n",
      "accuracy = 0.8518\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
